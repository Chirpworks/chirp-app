# Use the NVIDIA CUDA runtime as the base image
#FROM nvidia/cuda:11.8.0-runtime-ubuntu22.04
FROM --platform=linux/amd64 python:3.11-slim

# Set the working directory
WORKDIR /app

# Install necessary dependencies
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
    git \
    ffmpeg \
    python3-pip && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

COPY . .

ENV PYTHONPATH=/app

# Upgrade pip
RUN python3.11 -m pip install --upgrade pip

RUN pip install --no-cache-dir -r requirements_speaker_diarization.txt && rm -rf ~/.cache/pip

# Install PyTorch with CUDA support
# RUN pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --extra-index-url https://download.pytorch.org/whl/cu118
RUN pip install --no-cache-dir torch==2.0.0 torchvision==0.15.1 torchaudio==2.0.1 --index-url https://download.pytorch.org/whl/cpu && rm -rf ~/.cache/pip


# Install WhisperX
RUN pip --no-cache-dir install git+https://github.com/m-bain/whisperx.git && rm -rf ~/.cache/pip

# Expose a port if your worker exposes any HTTP interface (not strictly necessary for batch jobs)
# EXPOSE 8000

# Set the command to run your worker script.
# Replace 'your_worker_script.py' with the actual script that:
#   - downloads audio files from S3,
#   - runs diarization via WhisperX,
#   - and writes the transcript back to your meetings table.

CMD ["python3", "chirp-app/app/service/transcription/speaker_diarization_linux.py"]
